\section{Discussion}\label{sec4}

\subsection{Limitations}

The algorithms assume characteristic jump force profiles with clear takeoff/landing phases. Atypical movements (very low jumps, partial contacts) may be missed; errors occurred primarily in such edge cases. Fixed parameters optimized on our dataset may need recalibration for different sensor configurations, sampling rates, or surface characteristics. Pooling sensors into a single temporal trace discards spatial patterns (force asymmetries, center of pressure) that could enhance detection. The framework focuses on vertical jumps; extending to other tasks (sprints, change-of-direction) requires task-specific tuning.

\subsection{Future Work}

Future directions include: (1) extending to other movement tasks (sprints, change-of-direction) with task-specific parameter tuning; (2) adaptive parameter tuning based on real-time signal characteristics; (3) multi-sensor fusion leveraging spatial force patterns; (4) enhanced visualization tools for interpretability; and (5) full exploitation of real-time capabilities for immediate feedback during training.

\subsection{Real-World Deployment: Vault One}\label{subsec:vault_one}

The framework has been deployed in Vault One, a mobile application for trainers and athletes. The app provides real-time jump analysis on mobile devices, with data collection from anonymized users validating performance across diverse real-world conditions (varying surfaces, footwear, movement patterns). This practical deployment demonstrates the framework's robustness and real-world viability.

\section{Conclusion}\label{sec:conclusion}

This paper introduces a lightweight, interpretable framework for automated jump detection in ground reaction force data. By mimicking human intuition through simple signal-processing rules and physics-informed constraints, we achieve strong performance on 271 jumps across 27 participants, while maintaining $O(T)$ complexity suitable for real-time mobile deployment.

The framework's contributions are threefold: (1) encoding human-intuitive pattern detection as interpretable algorithms (threshold and derivative), providing an alternative to black-box machine learning; (2) comprehensive parameter optimization via Langevin sampling with grid search visualization for algorithm comparison; and (3) validation on real-world data through deployment in Vault One.

Through systematic evaluation of multiple approaches, we found that the derivative-based algorithm provides an excellent balance between performance and interpretability, achieving 28 errors with optimized parameters. The threshold-based algorithm offers complementary insights and serves as a baseline for comparison. Grid search visualizations reveal that the derivative algorithm has broader optimal parameter regions than threshold-based methods, suggesting rate-of-change features are more reliable indicators of jump events. While we explored several alternative approaches (correlation, hybrid, ensemble, landing derivative), the threshold and derivative algorithms emerged as the most practical and effective for deployment.

The framework addresses a critical gap in sports science workflows by enabling automated, protocol-flexible event detection in realistic training environments, eliminating the need for explicit start/stop sequences or highly standardized protocols. The interpretability of the framework is particularly valuable: practitioners can understand, verify, and adjust the algorithms based on domain knowledge, building trust essential for real-world deployment. The principles of physics-informed constraints, interpretable signal processing, and systematic parameter optimization via Langevin sampling are generalizable beyond vertical jumps, offering a template for developing detection algorithms for other sports science applications.

