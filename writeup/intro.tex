\newpage
\section{Introduction}\label{sec1}

Athletic training has become increasingly data-driven, with sports science workflows involving three key steps: (1) data collection, (2) analysis, and (3) translating insights into training interventions. While data collection has become easier through unobtrusive sensors and wireless hardware, the quality of analysis constrains practical deployment. This paper focuses on step (2): analyzing human performance data in a robust, interpretable, and practical manner.

Existing approaches require manual event labelling, which significantly increases the cost of data collection. At the professional athletics level, this cost adds friction to both the quantity and consistency of data collection; top programs often limit certain athletic tests that could provide tremendous day-to-day value because of the lengthy protocols surrounding manual analysis. For college athletics, local training gyms, and other contexts, this cost becomes prohibitive, preventing many athletes and trainers from accessing sports science feedback.

Effective performance analysis requires reliable identification of key events---takeoff, landing, and flight periods---enabling longitudinal tracking and metric extraction such as jump height, contact time, and reactive strength indices. We focus on ground reaction force (GRF) data from a 48-sensor capacitive pressure plate sampled at 50~Hz. Vertical jumps exhibit a characteristic signature: (i) force build-up during countermovement and propulsion, (ii) rapid unloading at takeoff, (iii) near-zero force while airborne, and (iv) rapid reloading at landing. While these patterns are visually obvious to human analysts, automated detection in noisy real-world conditions presents a significant challenge.

We propose a framework that mimics human intuition for pattern classification. Human analysts rely on qualitative cues to detect jumps: time in the air, rapid force production at takeoff and landing, and a repeated countermovement pattern of propulsion and absorption. We encode these qualitative cues into two complementary interpretable signal-processing algorithms: (1) \textbf{threshold-based}: identifies flight periods when force falls below a threshold, refined by physics-based bounds; (2) \textbf{derivative-based}: detects paired takeoff and landing events in the derivative signal, validated by in-air thresholds. Parameters are optimized via Langevin sampling for comprehensive multi-parameter optimization, with grid search providing visual loss landscapes for comparing algorithm performance. All algorithms operate in $O(T)$ time, enabling real-time mobile deployment.